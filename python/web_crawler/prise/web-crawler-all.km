{
    "root": {
        "data": {
            "id": "cjfw2lje28g0",
            "created": 1650541334948,
            "text": "爬虫学习知识点",
            "priority": 3,
            "expandState": "expand"
        },
        "children": [
            {
                "data": {
                    "id": "cjfwiapo9ko0",
                    "created": 1650542565210,
                    "text": "线程加速",
                    "expandState": "expand"
                },
                "children": [
                    {
                        "data": {
                            "id": "cjfwgkweaug0",
                            "created": 1650542430656,
                            "text": "主流的 Python 分布式爬虫还是基于 Scrapy 的，对接 Scrapy-Redis、Scrapy-Redis-BloomFilter 或者用 Scrapy-Cluster 等等"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwfb4a7h40",
                            "created": 1650542331001,
                            "text": "更牛逼的多线程 aiohttp gevent tornado"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwen38yao0",
                            "created": 1650542278696,
                            "text": "提高爬取速度使用多线程 库有theading multipocessing"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cjfwk0a4wxk0",
                    "created": 1650542699231,
                    "text": "加密解决加密",
                    "expandState": "expand"
                },
                "children": [
                    {
                        "data": {
                            "id": "cjfwcvu2hi80",
                            "created": 1650542141003,
                            "text": "解决加密，使用模拟浏览器爬取 puppeter pyppeteer selenium splash"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwc2ckctc0",
                            "created": 1650542076818,
                            "text": "加密参数 token sign等"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cjfwkbdbj2g0",
                    "created": 1650542723368,
                    "text": " 数据来源，数据解析",
                    "expandState": "expand"
                },
                "children": [
                    {
                        "data": {
                            "id": "cjfwazc55i00",
                            "created": 1650541991898,
                            "text": "现在数据来源可能是执行JavaScript Ajax ifame data 大多数是Ajax"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfw8vbqjts0",
                            "created": 1650541826438,
                            "text": "解析使用正则表达式，xpath beautifulsoup pyquery"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwdz2m9k00",
                            "created": 1650542226415,
                            "text": "Selenium 等工具，需要专门解决的问题 网站识别webdriver",
                            "expandState": "expand"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cjfwmg8uu9k0",
                    "created": 1650542890711,
                    "text": "初学爬虫",
                    "expandState": "expand"
                },
                "children": [
                    {
                        "data": {
                            "id": "cjfw6scll880",
                            "created": 1650541663232,
                            "text": "没有反爬虫手段requests"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwa26mm6w0",
                            "created": 1650541919731,
                            "text": "保存添加数据库"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cjfwrjahr3k0",
                    "created": 1650543289161,
                    "text": "验证码"
                },
                "children": [
                    {
                        "data": {
                            "id": "cjfwrugk54w0",
                            "created": 1650543313472,
                            "text": "图像验证码使用ORC"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwscrev3c0",
                            "created": 1650543353311,
                            "text": "图像识别，轨迹使用模拟正常人行为"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwsjrb3c00",
                            "created": 1650543368542,
                            "text": "难：分析JavaScript逻辑录入轨迹数据"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwty7fnag0",
                            "created": 1650543478356,
                            "text": "模拟浏览器拖动"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwu68fob40",
                            "created": 1650543495831,
                            "text": "用cookies爬"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfwuelt78o0",
                            "created": 1650543514054,
                            "text": "使用模拟浏览器连登录一起做了"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cjfwwrggqeg0",
                    "created": 1650543698757,
                    "text": "封装IP",
                    "note": "首先可以把市面上免费的代理用起来，自己搭建一个代理池，收集现在全网所有的免费代理，然后加一个测试器一直不断测试，测试的网址可以改成你要爬的网址。这样测试通过的一般都能直接拿来爬你的目标网站。我自己也搭建过一个代理池，现在对接了一些免费代理，定时爬、定时测，还写了个 API 来取，放在 GitHub 了：https://github.com/Python3WebSpider/ProxyPool，打好了 Docker 镜像，提供了 Kubernetes 脚本，大家可以直接拿来用。\n"
                },
                "children": []
            },
            {
                "data": {
                    "id": "cjfx6rs4c5c0",
                    "created": 1650544483103,
                    "text": "封账号"
                },
                "children": [
                    {
                        "data": {
                            "id": "cjfx7ib1hvc0",
                            "created": 1650544540844,
                            "text": "较好的方法，那就是分流",
                            "note": "，多个账号跑出来的 Cookies、Token 都放到这个池子里面，用的时候随机从里面拿一个"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cjfx8ftxdb40",
                    "created": 1650544613819,
                    "text": "App"
                },
                "children": [
                    {
                        "data": {
                            "id": "cjfx8pmk42g0",
                            "created": 1650544635142,
                            "text": "抓包工具了，Charles、Fiddler 一把梭，抓到接口之后，直接拿来模拟就行了。"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cjfx96ddte00",
                            "created": 1650544671592,
                            "text": "有加密参数"
                        },
                        "children": [
                            {
                                "data": {
                                    "id": "cjfx9ekuoxs0",
                                    "created": 1650544689458,
                                    "text": "比如 mitmproxy 直接监听接口数据。另一方面你可以走 Hook，比如上 Xposed 也可以拿到。"
                                },
                                "children": []
                            }
                        ]
                    },
                    {
                        "data": {
                            "id": "cjfx9nfvmc80",
                            "created": 1650544708748,
                            "text": "自动化"
                        },
                        "children": [
                            {
                                "data": {
                                    "id": "cjfx9teoz800",
                                    "created": 1650544721738,
                                    "text": "安卓原生的 adb 工具"
                                },
                                "children": [
                                    {
                                        "data": {
                                            "id": "cjfx9zxc9t40",
                                            "created": 1650544735926,
                                            "text": "Appium 现在已经是比较主流的方案了"
                                        },
                                        "children": []
                                    }
                                ]
                            }
                        ]
                    },
                    {
                        "data": {
                            "id": "cjfxah7zsko0",
                            "created": 1650544773575,
                            "text": "扣接口逻辑"
                        },
                        "children": [
                            {
                                "data": {
                                    "id": "cjfxatdcqyw0",
                                    "created": 1650544800021,
                                    "text": "逆向了，IDA Pro、jdax、FRIDA 等工具"
                                },
                                "children": []
                            }
                        ]
                    }
                ]
            },
            {
                "data": {
                    "id": "cjfxbe3ai400",
                    "created": 1650544845125,
                    "text": "智能化"
                },
                "children": [
                    {
                        "data": {
                            "id": "cjfxbwbdks80",
                            "created": 1650544884796,
                            "text": "提取详情页，一位朋友写的 GeneralNewsExtractor "
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cjfxc5mut0g0",
                    "created": 1650544905081,
                    "text": "运维",
                    "note": "作者：崔庆才丨静觅\n链接：https://www.zhihu.com/question/370284423/answer/1048042160\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n这里面，部署大家各有各的方法，比如用 Ansible 当然可以。如果用 Scrapy 的话有 Scrapyd，然后配合上一些管理工具也能完成一些监控和定时任务。不过我现在用的更多是还是 Docker + Kubernetes，再加上 DevOps 一套，比如 GitHub Actions、Azure Pipelines、Jenkins 等等，快速实现分发和部署。定时任务大家有的用 crontab，有的用 apscheduler，有的用管理工具，有的用 Kubernetes，我的话用 Kubernetes 就多一些了，定时任务也是很好实现。至于监控的话，也有很多，专门的一些爬虫管理工具自带了一些监控和报警功能。一些云服务也带了一些监控的功能。我用的是 Kubernetes + Prometheus + Grafana，什么 CPU、内存、运行状态，一目了然，报警机制在 Grafana 里面配一下也很方便，支持 Webhook、邮件甚至某钉。数据的存储和监控，用 Kafka、Elasticsearch 个人感觉也挺方便的，我主要用的是后者，然后再和 Grafana 配合起来，数据爬取量、爬取速度等等监控也都一目了然。"
                },
                "children": []
            }
        ]
    },
    "template": "default",
    "theme": "fresh-blue",
    "version": "1.4.43"
}